{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03a1476f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ce54a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()\n",
    "words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c08b28f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2184090a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#character to integer mapping & vice-versa\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i, s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s, i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5fd11f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "... -----> e\n",
      "..e -----> m\n",
      ".em -----> m\n",
      "emm -----> a\n",
      "mma -----> .\n",
      "olivia\n",
      "... -----> o\n",
      "..o -----> l\n",
      ".ol -----> i\n",
      "oli -----> v\n",
      "liv -----> i\n",
      "ivi -----> a\n",
      "via -----> .\n",
      "ava\n",
      "... -----> a\n",
      "..a -----> v\n",
      ".av -----> a\n",
      "ava -----> .\n",
      "isabella\n",
      "... -----> i\n",
      "..i -----> s\n",
      ".is -----> a\n",
      "isa -----> b\n",
      "sab -----> e\n",
      "abe -----> l\n",
      "bel -----> l\n",
      "ell -----> a\n",
      "lla -----> .\n",
      "sophia\n",
      "... -----> s\n",
      "..s -----> o\n",
      ".so -----> p\n",
      "sop -----> h\n",
      "oph -----> i\n",
      "phi -----> a\n",
      "hia -----> .\n"
     ]
    }
   ],
   "source": [
    "#building dataset\n",
    "\n",
    "block_size = 3\n",
    "X, Y = [], []\n",
    "for w in words[:5]:\n",
    "    \n",
    "    print(w)\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        print(f\"{''.join(itos[i] for i in context)} -----> {itos[ix]}\")\n",
    "        context = context[1:] + [ix] #kinda like rolling window, crop & append\n",
    "        \n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d099b248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]), torch.int64, torch.Size([32]), torch.int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X.dtype, Y.shape, Y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51b9fffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the embedding lookup table\n",
    "C = torch.randn((27,2)) #reduces the dimensions of the input vector to 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1f105f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[X]\n",
    "emb.shape\n",
    "\n",
    "# X[13, 2] -> represents 1\n",
    "# emb[X[13,2]] -> returns the embedded value for the X[13, 2] element, which is 1\n",
    "# emb[1] -> return the lower dimensional embedding for the integer input 1\n",
    "# outputs of prev 2 are both equal = \n",
    "# tensor([[ 1.5126,  1.2000],\n",
    "#         [ 1.5126,  1.2000],\n",
    "#         [-0.7919, -0.1932]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c259eb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = torch.randn((6, 100)) \n",
    "b1 = torch.randn(100)\n",
    "# 6 -> 3 inputs of 2D embeddings => 2x3 = 6 input neurons\n",
    "# 100 -> hidden layer inputs, chosen randomly - hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e776f596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8064,  0.8649,  0.9566,  ..., -0.4694,  0.9214, -0.8978],\n",
       "        [ 0.3819, -0.7671, -0.8991,  ..., -0.8792,  0.7239, -0.8545],\n",
       "        [ 0.8336,  0.2300, -0.1703,  ..., -0.9996, -0.9830,  0.2964],\n",
       "        ...,\n",
       "        [ 0.8771, -0.4381,  0.9549,  ..., -1.0000, -0.9967, -0.9179],\n",
       "        [ 0.9720,  0.2754,  0.9995,  ...,  0.6776, -0.9609,  0.9840],\n",
       "        [ 0.9274, -0.8437,  0.9696,  ...,  0.9955, -0.0239, -0.1782]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = torch.tanh(emb.view(-1,6)@W1 + b1) \n",
    "# tensorObject.view alters the inner storage layout to represent the tensor in given dimension\n",
    "# In this case, we need 6 inputs (3x2), so we're essentially concatenating them to match that input dimension\n",
    "# & multiplying it with the weights initialized for the first layer.\n",
    "# The output has 100 tanh activation funciton outputs of the hidden layer (refer Bengio et al. 2003)\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3ab6a37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = torch.randn((100, 27))\n",
    "b2 = torch.randn(27)\n",
    "# weights and biases for the softmax layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ed73a6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = h @ W2 + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cf27c51b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4e797ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = logits.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1c098843",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = counts/counts.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8457db60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
       "         1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bf69e7f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14.9209)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = -torch.log(prob[torch.arange(32), Y]).mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfaba4f",
   "metadata": {},
   "source": [
    "## Putting MLP together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "91617a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building dataset\n",
    "\n",
    "block_size = 3\n",
    "X, Y = [], []\n",
    "for w in words:\n",
    "    \n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        context = context[1:] + [ix] #kinda like rolling window, crop & append\n",
    "        \n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9034a936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([228146, 3]), torch.Size([228146]))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape #dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "49d64ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e5537d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = torch.randn((27, 2), generator=g)\n",
    "W1 = torch.randn((6, 100), generator=g)\n",
    "b1 = torch.randn(100, generator=g)\n",
    "W2 = torch.randn((100, 27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "params = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c0b67125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3481"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.nelement() for p in params) # total parameters in the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "cdf28816",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in params:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "fbac86a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.504465103149414\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    \n",
    "    #minibatch\n",
    "    ix = torch.randint(0, X.shape[0], (32, )) # batch of size 32\n",
    "    \n",
    "    #forward prop\n",
    "    emb = C[X[ix]]\n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, Y[ix]) \n",
    "    # does the same softmax calc we did. more efficient since there's no creation of extra tensors + more efficient\n",
    "#     print(loss.item())\n",
    "\n",
    "    #backward prop\n",
    "    for p in params:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    #update\n",
    "    for p in params:\n",
    "        p.data += -0.1 * p.grad\n",
    "        \n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "43420681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.6897, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#overall loss\n",
    "emb = C[X]\n",
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1)\n",
    "logits = h @ W2 + b2\n",
    "loss = F.cross_entropy(logits, Y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dc22ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
